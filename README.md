# COERCE - A Measure of Early Pass Rush Pressure
Welcome! This repository contains code for my submission to the 2023 Big Data Bowl. Details on the competition are [available here](https://www.kaggle.com/competitions/nfl-big-data-bowl-2023).

You can [read my submission to the competition here.]() 

## Technical Requirements
This project was completed using `R 4.2.2` in `RStudio 2022.07.2`.  

## Data
Data is available from the [Big Data Bowl Kaggle page](https://www.kaggle.com/competitions/nfl-big-data-bowl-2023/data). Each `.csv` file should be placed in the `data` directory. 

## Instructions
Due to circumstances beyond my control (ie. starting this project too late, poor time management and procrastination - definitely not my fault...) there is sadly no one script to run the entire workflow of the project. It won't be that hard to do, basically filepaths would need to be streamlined and various scripts written as functions, but I don't have time to do that before the competition submission. So instead, you can follow the below instructions in order to import the data, train the XGBoost models and create _COERCE_ rankings:

1. Put the relevant csv files in the `data` directory.
2. Run `import_data.R`. This loads the files, and does some feature engineering on the tracking data.
3. Run `plotting.R`. This contains the code to plot visualisations of the tracking data.
4. Run `create_training_data_for_team_level_hhs_model.R` and `create_training_data_for_rusher_level_hhs_model.R`. These format the training data for the pressure models. The training sets are outputted to the `output/features` directory.
5. Run `train_team_level_hhs_model.R` and `train_rusher_level_hhs_model.R`. Note, you will need to update the filepaths at the top of these scripts to read the training data that was exported from the previous step. These will output the models and probability predictions for the tracking data to the `output/models` directory. 
6. Run `coerce_calculations.R`. This will create the _COERCE_ rankings, and output plots and tables of the results. Note, again you will need to update the relevant filepaths to read from the models and predictions generated by the previous step. 

And that should be it!

If there are any issues, questions or comments feel free to reach out at @ianasta23 on Twitter or `iastalosh@gmail.com` . 

Thanks for reading!